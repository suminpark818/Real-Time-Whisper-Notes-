# Real-Time Whisper Notes  
Flask + Whisper + Ollama Real-Time Speech Summary Web App

A simple web application that records audio directly from the browser, transcribes it with Whisper, and summarizes the transcript using a local LLM (Ollama).  
This small project works as a “personal meeting auto-note generator.”

---

## Features

- Record microphone audio in the browser (MediaRecorder API)
- Send audio to a Flask backend in real time
- Transcribe speech using Whisper (local, CPU-based)
- Summarize the transcript using an Ollama model (e.g., Llama 3.1)
- Display both transcript & summary instantly in the UI

---

## 1. Tech Stack

**Backend**
- Python, Flask  
- Whisper (`openai-whisper`) for STT  
- Ollama (local LLM inference)

**Frontend**
- HTML, CSS  
- Vanilla JS (MediaRecorder for mic input)

**Other**
- ffmpeg (required for Whisper audio processing)

---

## 2. Project Structure

```

RealTimeWhisperNotes/
├── app.py                   # Flask server + Whisper + Ollama summarizer
├── templates/
│   └── index.html           # Main UI page
└── static/
├── recorder.js          # Browser microphone recorder
└── style.css            # Basic styling

````

---

## 3. Setup

### 3.1 Conda Environment (optional but recommended)

```bash
conda create -n whisper python=3.11
conda activate whisper
````

### 3.2 Install Python Dependencies

```bash
pip install flask
pip install openai-whisper
```

Install ffmpeg (macOS Homebrew):

```bash
brew install ffmpeg
```

### 3.3 Install Ollama & Pull Model

Install from [https://ollama.com](https://ollama.com)
Then download a model:

```bash
ollama pull llama3.1:8b
```

---

## 4. How It Works (app.py Overview)

`app.py` handles:

1. Serving the main webpage (`index.html`)
2. Receiving the recorded WebM audio from the browser
3. Saving it temporarily
4. Running Whisper → text transcription
5. Sending the transcript to Ollama → summary generation
6. Returning JSON response:

   ```json
   {
     "transcript": "...",
     "summary": "..."
   }
   ```

Example Ollama call from Python:

```python
prompt = f"Summarize the following transcript in clear bullet points:\n\n{transcript}"

ollama_result = subprocess.run(
    ["ollama", "run", "llama3.1:8b"],
    input=prompt,
    text=True,
    capture_output=True
)

summary = ollama_result.stdout.strip()
```

---

## 5. Running the App

From inside the project folder:

```bash
cd /Users/sumin/Desktop/RealTimeWhisperNotes
conda activate whisper
python app.py
```

The server runs (in your current config) on:

```
http://127.0.0.1:5050
```

Open in your browser.

---

## 6. How to Use

1. Visit the running server URL
2. Click **Start Recording**
3. Speak into your microphone
4. Click **Stop Recording**
5. The server:

   * Receives the audio
   * Transcribes using Whisper
   * Summarizes using Ollama
6. The page displays:

* **Transcript**: raw STT text
* **Summary**: concise summary generated by LLM

---

## 7. Common Issues + Fixes

### ❗ Port Already in Use (`Address already in use`)

Another process is using port 5000/5050.
Change port inside `app.py`:

```python
app.run(host="0.0.0.0", port=5050, debug=True)
```

Or switch to another port like 5051, 8000, 9000, etc.

---

### ❗ Browser Mic Permission Denied

If recording doesn’t work:

* Allow microphone permissions in the browser
* Ensure HTTPS is not required (local HTTP is fine)

---

### ❗ Whisper is Slow

Current model:

```python
model = whisper.load_model("tiny")
```

You can try:

* `base`: better accuracy, slower
* `small`: much better, significantly slower

---

## 8. Potential Improvements

* Add selectable summary styles (bullet / paragraph / action items)
* Multi-language support with translation
* Save transcript/summary as local files or store in a database
* Waveform visualization UI
* Meeting history list

---

## 9. License / Usage Note

This project is intended for personal, educational, and portfolio use.
If used commercially or deployed at scale, check the licenses for:

* Whisper
* Ollama models
* Other dependencies
